Overall
=======

- Parse graph & build adjacency lists.
- Parse the nodes file to get the number of paths to print and a list of start
  nodes.
- For each start node:
  - Find the first N maximal paths from the start node S and print them out
  - Calculate the number of maximal paths from the start node and print it out.


Counting the number of maximal paths
===================================

- Hybrid breadth-first and depth-first search.
- Breadth first to find a list of starting points for the depth-first search.
- Depth first search in parallel for each of the starting points.

- Breadth first search.
- The list of starting points has to be large enough to be worth parallelising.
- First, push the start node onto the list.
- Build up the list by repeatedly popping the node at the front of the list and
  replacing it with all of it's children until the list gets big enough.
- Big enough is a multiple of the number of hardware threads available
  (currently 4 times).

- Depth first search walks the node graph recursively.
- Flag the current node as part of the path.
- Get the edge list for the current node.
- For each "next node" in the edge list:
  - If it's already part of the current path, ignore it.
  - Otherwise, do a depth first search from it.
- If the edge list didn't contain any new nodes, we've found a maximal path.


Data structures
===============

- Graph
  - Iterating over children of a node must be as fast as possible.
  - Using a semi-sparse representation: a per-node adjacency list (not an
    adjacency matrix).

- Path
  - Need to be able to find out what nodes are on the path, in what order.
  - Checking whether a particular node is already on the path should be quick.
  - Use a tree representation, so we can share common initial subpaths.
  - Use a bottom-up tree representation (each tree node points to it's parent,
    parents don't point to their children).
  - Use a separate boolean array to record whether a node is already on the
    path. There's one of these per thread.
  

Notes
=====

- Counting all the maximal paths, instead of finding some "best" path (longest,
  shortest, whatever), means that there are very few algorithmic optimisations
  we can make.
- It comes down to a brute-force approach, where depth first search wins.
- The trick is to parallelise the depth-first search efficiently, which means
  the coarsest granularity that allows us to keep all threads busy.

